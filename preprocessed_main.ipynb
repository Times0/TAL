{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huuH_crawrIE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('train.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjNRJFPRwrIF"
      },
      "source": [
        "# General informations about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSrIzSTswrIF",
        "outputId": "d80a8216-caf6-4b1c-dd4e-894774ea487b"
      },
      "outputs": [],
      "source": [
        "print(df.keys())\n",
        "print(df['category'].value_counts())\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# only select 76 values for each category\n",
        "df = df.groupby('category').head(76)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHW8A9y4wrIG"
      },
      "source": [
        "## Let's see how the length of the headlines and texts are distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "QWZg98vGwrIG",
        "outputId": "ddebfeb5-5d5e-47e2-f43c-d5e45b097e57"
      },
      "outputs": [],
      "source": [
        "df['headline'].apply(len).plot.hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "yJfRdUQ3wrIG",
        "outputId": "6ce4d93c-b9a9-4851-9e7a-8233bb5cdf63"
      },
      "outputs": [],
      "source": [
        "df[\"text\"].apply(len).plot.hist(bins=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdOH31-wwrIG"
      },
      "source": [
        "### Findings\n",
        "- Url not relevant, we can drop this column\n",
        "- Technology is clearly underrepresented in the dataset (1/5 of the support of other categories)\n",
        "- texts lengths are in the range 0-10_000 characters, very small minority goes up to 40_000 chars.\n",
        "\n",
        "We will need to take those informations into account to train the best model possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJa62me0yFzo",
        "outputId": "5bc51d6b-fa66-43f9-e1e6-909cef170c13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\spoto\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\spoto\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8ras0RoN5yoR"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m X, y\n",
            "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "X = df[['headline', 'text']]\n",
        "y = df[\"category\"]\n",
        "\n",
        "X_train, y_train = X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjnraEX6xBF0"
      },
      "source": [
        "## Vectorization with Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg8foDQFy43-",
        "outputId": "e1732741-8fd1-423e-9243-0c0335c855ae"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Tokenization function with stemming\n",
        "stemmer = SnowballStemmer('french')\n",
        "\n",
        "def tokenize_with_stemming(text):\n",
        "    text = text.lower()  # Lowercasing\n",
        "    tokens = word_tokenize(text, language='french')  # Tokenization\n",
        "    tokens = [stemmer.stem(token) for token in tokens]  # Stemming\n",
        "    return tokens\n",
        "\n",
        "\n",
        "french_stopwords = stopwords.words(\n",
        "    'french') + list(string.punctuation) + [\"''\", '``', '...', '’', '``', '«', '»', '``']\n",
        "\n",
        "# in order for the stop words to be consistent with preprocessing\n",
        "french_stopwords = [stemmer.stem(word) for word in french_stopwords]\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize_with_stemming,\n",
        "                             stop_words=french_stopwords,\n",
        "                             max_features=800)\n",
        "\n",
        "# X_train_tfidf = vectorizer.fit_transform(\n",
        "#     X_train['headline'] + ' ' + X_train['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "nUMPIHSezE8H",
        "outputId": "36b4b8b1-12a4-43e5-aba9-59d498de8770"
      },
      "outputs": [],
      "source": [
        "desc_bow = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "# desc_bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pt2kK8OpwrIH"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "col_trans = ColumnTransformer(\n",
        "    [('headline', vectorizer, 'headline'),\n",
        "     ('text', vectorizer, 'text')],\n",
        ")\n",
        "\n",
        "pipe = make_pipeline(col_trans, RandomForestClassifier())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "_tO-PmU3wrIH",
        "outputId": "af2fd2ef-1db1-4c8a-8008-2545bbe8bd54"
      },
      "outputs": [],
      "source": [
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH8NEs5LwrII",
        "outputId": "46f591e1-2c9a-42a3-bc37-23902fcd15cf"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('test.tsv', sep='\\t')\n",
        "\n",
        "# show count of each category\n",
        "print(df_test['category'].value_counts())\n",
        "\n",
        "X_test = df_test[['headline', 'text']]\n",
        "y_test = df_test[\"category\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TJYkJa0wrII",
        "outputId": "dd3c817e-4d06-4f90-96ee-26dd8d5c06bb"
      },
      "outputs": [],
      "source": [
        "y_pred = pipe.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show wrong predictions\n",
        "df_test['predicted_category'] = y_pred\n",
        "df_test['correct'] = df_test['category'] == df_test['predicted_category']\n",
        "\n",
        "df_test[df_test['correct'] == False].head()[['headline', \"category\", \"predicted_category\"]].to_clipboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "C_Dul0brwrII",
        "outputId": "d7a2c3cd-1b14-4880-d3c0-e074768db926"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
        "            xticklabels=df['category'].unique(), yticklabels=df['category'].unique())\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KToNn4YtwrII"
      },
      "source": [
        "Let's see what type of model is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H92RTA-1z59N"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "models = [\n",
        "    ('Baseline', DummyClassifier(strategy='most_frequent')),\n",
        "    ('Multinomial NB', MultinomialNB()),\n",
        "    ('CART', DecisionTreeClassifier()),\n",
        "    ('LR', LogisticRegression()),\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Random forest', RandomForestClassifier())\n",
        "]\n",
        "\n",
        "for name, model in models:\n",
        "    pipe = make_pipeline(col_trans, model)\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    print(f'{name}: {accuracy_score(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHlIiEIcgG8A"
      },
      "source": [
        "# Cross validation for LR and Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqpTsTpf0DqR",
        "outputId": "422e2c2e-42ff-4004-ff3a-7849e5ff2faa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def evaluate_model(name, model, X, y):\n",
        "    pipe = make_pipeline(col_trans, model)\n",
        "    scores = cross_val_score(pipe, X, y, cv=5)  # 5-fold cross-validation\n",
        "    print(f'{name}: Mean Accuracy: {scores.mean()}')\n",
        "\n",
        "evaluate_model(\"LR\", LogisticRegression(), X_train, y_train)\n",
        "evaluate_model(\"Random Forest\", RandomForestClassifier(), X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q18zAzKM2Ma9"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TST82LR3q-V",
        "outputId": "030a6951-44fc-44dd-8a45-4cf05adb639e"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmIiOYkm2QsI"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "spacy_stopwords = nlp.Defaults.stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q40D5Tnb3h8z"
      },
      "outputs": [],
      "source": [
        "# Custom tokenizer function using spaCy for tokenization and lemmatization\n",
        "def spacy_tokenizer(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if token.text.lower() not in spacy_stopwords and token.is_alpha]\n",
        "    return tokens\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer,\n",
        "                             max_features=1000)\n",
        "\n",
        "X = df[['headline', 'text']]\n",
        "y = df[\"category\"]\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X['headline'] + ' ' + X['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "aWMqfMNN5CdZ",
        "outputId": "074225b9-7c91-4e5c-cb23-71be2b6f669e"
      },
      "outputs": [],
      "source": [
        "desc_bow = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "desc_bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "iyApFsQ15QCp",
        "outputId": "e4703556-1085-46f8-c836-a383bc2f78f9"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "col_trans = ColumnTransformer(\n",
        "    [('headline', vectorizer, 'headline'),\n",
        "     ('text', vectorizer, 'text')],\n",
        ")\n",
        "\n",
        "pipe = make_pipeline(col_trans, RandomForestClassifier())\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3bUzzqnMG9n",
        "outputId": "7fd57a1a-29f5-4c88-ccf4-e82422a6f40c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category\n",
            "business      100\n",
            "health        100\n",
            "politics      100\n",
            "sports        100\n",
            "technology     22\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv('test.tsv', sep='\\t')\n",
        "\n",
        "# show count of each category\n",
        "print(df_test['category'].value_counts())\n",
        "\n",
        "X_test = df_test[['headline', 'text']]\n",
        "y_test = df_test[\"category\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgqzJMFN55bd",
        "outputId": "59c01c47-a376-4878-8522-3a37aa28eefd"
      },
      "outputs": [],
      "source": [
        "y_pred = pipe.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "l8h-UCv857l-",
        "outputId": "2dfb2862-8a5f-4031-8507-02886f3b871f"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
        "            xticklabels=df['category'].unique(), yticklabels=df['category'].unique())\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8YvWaPS59KK",
        "outputId": "506b4249-a97b-474c-c535-5e55cca9ac62"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "models = [\n",
        "    ('Baseline', DummyClassifier(strategy='most_frequent')),\n",
        "    ('Multinomial NB', MultinomialNB()),\n",
        "    ('CART', DecisionTreeClassifier(class_weight='balanced')),\n",
        "    ('LR', LogisticRegression()),\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Random forest', RandomForestClassifier())\n",
        "]\n",
        "\n",
        "for name, model in models:\n",
        "    pipe = make_pipeline(col_trans, model)\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    print(f'{name}: {accuracy_score(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C6Dy63mXSLs"
      },
      "source": [
        "# Cross validation for LR and Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dWKyB2HXTwn",
        "outputId": "65658194-2417-4431-f7f4-f76c5b28380c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Programmation\\School\\TPS\\TAL-1\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Programmation\\School\\TPS\\TAL-1\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Programmation\\School\\TPS\\TAL-1\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Programmation\\School\\TPS\\TAL-1\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Programmation\\School\\TPS\\TAL-1\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR: Mean Accuracy: 0.8080952380952381\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def evaluate_model(name, model, X, y):\n",
        "    pipe = make_pipeline(col_trans, model)\n",
        "    scores = cross_val_score(pipe, X, y, cv=5)  # 5-fold cross-validation\n",
        "    print(f'{name}: Mean Accuracy: {scores.mean()}')\n",
        "\n",
        "evaluate_model(\"LR\", LogisticRegression(), X_test, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5QOV5uChNUV",
        "outputId": "c216c1a5-9c7b-4e92-8e97-82e718ee9805"
      },
      "outputs": [],
      "source": [
        "evaluate_model(\"LR\", LogisticRegression(), X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0xqLWM3gUM9",
        "outputId": "874172ed-4bce-4c34-d0db-26d20051031d"
      },
      "outputs": [],
      "source": [
        "evaluate_model(\"Random Forest\", RandomForestClassifier(), X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DMWP46khQdD",
        "outputId": "7918697e-a957-4720-a58b-2171844d3ddf"
      },
      "outputs": [],
      "source": [
        "evaluate_model(\"Random Forest\", RandomForestClassifier(), X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5MdzfwK2mAz"
      },
      "source": [
        "## TO DO : Different tokens frequency threshold (Tf-Idf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3wnLHZl3Hbd"
      },
      "source": [
        "## TO DO : la validation croisée stratifiée (pour les ensembles de données déséquilibrés en termes de distribution de classes, la validation croisée stratifiée garantit que chaque sous-ensemble de données conserve la même distribution de classes que l'ensemble de données original.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRsFO_bY3VAH"
      },
      "source": [
        "## TO DO : autres metriques pour comparer les modeles avec la CV (rapport)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
